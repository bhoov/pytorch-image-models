{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "084bd834-72bb-4df5-b59d-4cb80a76ea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9904860-7ee7-4dc2-80ad-07e0d70dcddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from timm.utils.lightning_train import LitTimm # WARNING: This file is COPIED from the one used for actual training\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e7c9b77-f81d-41b3-9b51-5cb8011ae314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logdir = Path(\"/gpfs/u/home/DAMT/DAMThvrb/scratch/tb_logs/\")\n",
    "ckpt = \"/gpfs/u/home/DAMT/DAMThvrb/scratch/tb_logs/TAVT01/tavt_newatt_nobiases_weightsum/checkpoints/last.ckpt\"\n",
    "model = LitTimm.load_from_checkpoint(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e53c624a-287f-4254-88d0-d87a7203c81b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.2025, -0.3117, -0.2029, -0.1456, -0.2612, -0.1953, -0.2297, -0.5367,\n",
       "        -0.1950, -0.2246, -0.6338, -0.2383], requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.blocks.block.attn.weight_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f668d2c-307d-4cd9-b420-9dde5d3b1e40",
   "metadata": {},
   "source": [
    "Analysis plan\n",
    "\n",
    "- Analyze the weighted sums trained over the weekend\n",
    "- Compare with K=V , norm of the value matrix\n",
    "- Check values of kqt1\n",
    "\n",
    "I will need 2 that work really well, and 2 that kinda work but are our method\n",
    "\n",
    "What if one (both) of the energy terms are supposed to be negative?\n",
    "    - Wouldn't the model just learn the negative values themselves?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41d736bf-119c-4057-b9e5-3d8e6ce5beb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-4.0361e-03, -8.6164e-03, -4.9885e-03, -4.4652e-01, -5.5194e-01,\n",
       "         8.9605e-01, -3.6049e-03, -5.1600e-03, -6.5746e-01, -1.7637e-03,\n",
       "        -5.8060e-05, -5.6285e-03], requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = \"/gpfs/u/home/DAMT/DAMThvrb/scratch/tb_logs/TAVT02/tavt_newatt_weightsum_eneg4clipinit-True/checkpoints/last.ckpt\"\n",
    "model = LitTimm.load_from_checkpoint(ckpt)\n",
    "model.model.blocks.block.attn.weight_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d71b0c1-ccb4-46b8-bbcd-34b1818a3a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4455, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = \"/gpfs/u/home/DAMT/DAMThvrb/scratch/tb_logs/TAVT02/tavt_newatt_weightsum_eneg3clipinit-False/checkpoints/last.ckpt\"\n",
    "model = LitTimm.load_from_checkpoint(ckpt)\n",
    "model.model.blocks.block.attn.weight_sum.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0293ef48-90d2-47d0-9020-f1719a0284e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4931, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = \"/gpfs/u/home/DAMT/DAMThvrb/scratch/tb_logs/TAVT02/tavt_newatt_weightsum_eneg3clipinit-True/checkpoints/last.ckpt\"\n",
    "model = LitTimm.load_from_checkpoint(ckpt)\n",
    "model.model.blocks.block.attn.weight_sum.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e403dfd-422e-4aac-9c88-b9dad07b50f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_headweight_training=True\n",
    "def filter_k(k):\n",
    "    c1 = \"betas\" not in k\n",
    "    if no_headweight_training:\n",
    "        c2 = \"weight_sum\" not in k\n",
    "        return c1 and c2\n",
    "    return c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8103165d-f9ef-4145-a7dd-d88d0643c915",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [k for k, v in model.model.named_parameters() if filter_k(k)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c109e1ce-c765-43e0-b5d3-4fee9eeeafbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:timm] *",
   "language": "python",
   "name": "conda-env-timm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
